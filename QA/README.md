<h1>Question Answering System</h1>

<h2> Aim </h2>
<b>Build a question answering system, that process a story and qustions related to it and produces an answer.</b>

<img src="https://github.com/Indu4598/NLP/blob/master/QA/Architecture.png" width="500" />

<h3>Root Match</h3>
  1. We extracted the root words of the question and each sentences. <br/>
  2. Sentences were rewarded based on the number of common roots it had with the question. <br/>
 
<h3>Word Match</h3>
  1. The sentence was rewarded based on the common words it shared with the question. <br/>
  2. A verb got the sentence 6 points, a proper noun got 1 point and any other word got 3 points. <br/>

<h3>Question Type Classification</h3>
  1. We then extracted the question type and applied corresponding rules for each type of question. <br/>
  2. Sentences which satisfied the rules were again rewarded. <br/>
  
<h3>Rule Based Scoring</h3>
  1. After we determined the question type, we applied rule-based scoring. <br/>
  2. For example, if the question type was where - sentences with clue about position were rewarded. Clues about position included preposition and NER tags like ORG, GPE, and LOC. <br/>

<h3>Answer Extraction</h3>
  1. Based on the cumulative scores of root-match, word-match, and rule-based scoring, the sentence with the highest score was selected as a sentence containing the answer.  <br/>
  2. NER-tagging was then applied on the sentences. Depending upon the classification of the question type words corresponding to the appropriate tags were append to the answer.  <br/>

<h2> Emphasis/Originality </h2>

<img src="https://github.com/Indu4598/NLP/blob/master/QA/Questions.png" width="500" />

<h4>named-entity recognition tagging </h4>
<b>Question:</b>  If you were a student, how much would a club membership cost you? <br/>
<b>Expected answer:</b>  $135 a year <br/>
<b>Candidate sentence:</b>  Memberships cost $180 a year for adults and $135 for students and seniors.<br/>
<b>Answer:</b>  $180 $135 <br/>


<b>Description:</b> After the selection of candidate sentence, NER tagging is applied to extract the answer. For Example, the above question asks for quantity, extract all th words that have been NER tagged as currency from the sentence. So the final extracted answer is $180 $135. <br/>
Precision = 0.5 Recall = 0.33 F-Score =  0.3976 <br/>

<h4>eliminate common words and stopwords </h4>
<b>Question:</b>  Why does the Queen Mum face less media pressure than other members of the royal family?
 <br/>
<b>Expected answer:</b> because she is so admired <br/>
<b>Candidate sentence:</b> Because she is so admired, she does not face the same media pressure the royal family members do.<br/>
<b>Answer:</b> Because admired <br/>
<b>Description:</b> Generally to handle why questions, eliminate all the stop words and the common words ( words matched for the question and the cnadidate sentences) <br/>
Precision = 1 Recall = 0.2 F-Score = 0.3333 <br/>

<h4>proper noun overlap</h4>
<b>Question:</b> Who is the principal of South Queens Junior High School? <br/>
<b>Expected answer:</b> Betty Jean Aucoin <br/>
<b>False candidate sentence:</b> South Queens Junior High School is taking aim at the fitness
market.<br/>
<b>Candidate sentence</b>: Principal Betty Jean Aucoin says the club is a first for a Nova Scotia
public school.<br/>
<b>Answer: </b> Betty Jean Aucoin <br/>
<b>Description:</b> The main idea is to reward sentence that has more common word match with question. However, rewarding sentences with proper noun overlap gives a false candiadte sentence. <br/>
Precision = 1 Recall = 1 F-Score = 1 <br/>

<img src="https://github.com/Indu4598/NLP/blob/master/QA/Evaluation.png" width="500" />

Recall (R):the number of correct words generated by the system divided by the total numberof words in the answer string.<br/>
Precision (P):the number of correct words generated by the system divided by the total numberof words generated by the system..<br/>
F-measure:F(R,P) =2×P×R/P+R.<br/>
